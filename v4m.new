#!/bin/bash

# v4m - VM Manager for macOS
# Usage: v4m <command> [options]

set -e

cleanup() {
    tput cnorm 2>/dev/null || true
}
trap cleanup EXIT INT TERM

V4M_DIR="$HOME/.v4m"
IMAGES_DIR="$V4M_DIR/images"
VMS_DIR="$V4M_DIR/vms"
DEFAULT_IMAGE="debian12"
DEFAULT_USER="user01"
DEFAULT_MEMORY="4096"
DEFAULT_CPUS="4"
DEFAULT_DISK_SIZE="20G"

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
GRAY='\033[0;90m'
NC='\033[0m'

show_spinner() {
    local message="$1"
    local duration="${2:-30}"
    local spin='⠋⠙⠹⠸⠼⠴⠦⠧⠇⠏'
    local spin_length=${#spin}
    
    tput civis >&2
    for i in $(seq 1 $duration); do
        local spinner_char=$((i % spin_length))
        printf "\r${BLUE}${spin:$spinner_char:1}${NC} $message " >&2
        sleep 0.033
    done
    tput cnorm >&2
}

log_info() {
    echo -e "${BLUE}ℹ${NC} $1"
}

log_success() {
    echo -e "${GREEN}✓${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}⚠${NC} $1"
}

log_error() {
    echo -e "${RED}✗${NC} $1"
}

check_root() {
    if [ "$EUID" -ne 0 ]; then
        log_error "This operation requires sudo privileges"
        exit 1
    fi
}

init_dirs() {
    mkdir -p "$IMAGES_DIR" "$VMS_DIR"
}

generate_vm_name() {
    local adjectives=("fast" "quick" "smart" "bright" "cool" "swift" "agile" "sharp" "clever" "rapid")
    local nouns=("vm" "box" "node" "server" "instance" "machine" "host" "system" "unit" "engine")
    local adj=${adjectives[$RANDOM % ${#adjectives[@]}]}
    local noun=${nouns[$RANDOM % ${#nouns[@]}]}
    local num=$((RANDOM % 100))
    echo "${adj}-${noun}-${num}"
}

generate_password() {
    openssl rand -base64 12 | tr -d "=+/" | cut -c1-12
}

sanitize_vm_name() {
    local name="$1"
    echo "$name" | tr '[:upper:]' '[:lower:]' | sed 's/[^a-z0-9-]/-/g' | sed 's/--*/-/g' | sed 's/^-\|-$//g'
}

get_image_url() {
    case "$1" in

        # "alpine")
        #     echo "https://dl-cdn.alpinelinux.org/alpine/v3.22/releases/cloud/generic_alpine-3.22.1-aarch64-uefi-tiny-r0.qcow2"
        #     ;;
        
        "debian12")
            echo "https://cloud.debian.org/images/cloud/bookworm/latest/debian-12-generic-arm64.qcow2"
            ;;
        "debian13")
            echo "https://cloud.debian.org/images/cloud/trixie/latest/debian-13-generic-arm64.qcow2"
            ;;
        "ubuntu22")
            echo "https://cloud-images.ubuntu.com/releases/22.04/release/ubuntu-22.04-server-cloudimg-arm64.img"
            ;;
        "ubuntu24")
            echo "https://cloud-images.ubuntu.com/releases/24.04/release/ubuntu-24.04-server-cloudimg-arm64.img"
            ;;
        # "fedora42")
        #     echo "https://ftp.uni-stuttgart.de/fedora/releases/42/Cloud/aarch64/images/Fedora-Cloud-Base-Generic-42-1.1.aarch64.qcow2"
        #     ;;
        
        *)
            echo ""
            ;;
    esac
}

generate_mac() {
    printf "52:54:00:%02x:%02x:%02x\n" $((RANDOM%256)) $((RANDOM%256)) $((RANDOM%256))
}

hash_password() {
    local password="$1"
    openssl passwd -6 "$password"
}

# Socket VMNet Management
socket_vmnet_status() {
    # Get homebrew prefix dynamically
    local brew_prefix
    if command -v brew >/dev/null 2>&1; then
        brew_prefix=$(brew --prefix)
    else
        brew_prefix="/opt/homebrew"  # fallback
    fi
    
    local socket_path="$brew_prefix/var/run/socket_vmnet"
    
    # Check if socket_vmnet process is running
    if pgrep -f socket_vmnet >/dev/null 2>&1; then
        # Also verify the socket file exists and is accessible
        if [ -S "$socket_path" ]; then
            return 0
        else
            log_warning "socket_vmnet process running but socket not accessible at $socket_path"
            return 1
        fi
    fi
    
    return 1
}

socket_vmnet_start() {
    if ! socket_vmnet_status; then
        log_info "Starting socket_vmnet daemon (requires sudo for initial setup)..."
        
        # Get homebrew prefix
        local brew_prefix
        if command -v brew >/dev/null 2>&1; then
            brew_prefix=$(brew --prefix)
        else
            brew_prefix="/opt/homebrew"
        fi
        
        # Ensure the run directory exists with correct permissions
        local run_dir="$brew_prefix/var/run"
        if [ ! -d "$run_dir" ]; then
            sudo mkdir -p "$run_dir"
            sudo chown "$(whoami):$(id -gn)" "$run_dir"
            sudo chmod 755 "$run_dir"
        fi
        
        if sudo brew services start socket_vmnet; then
            log_success "socket_vmnet daemon started"
            sleep 3  # Give it more time to start and create socket
            
            # Verify socket was created
            local socket_path="$brew_prefix/var/run/socket_vmnet"
            if [ ! -S "$socket_path" ]; then
                log_warning "Socket not created after startup, waiting longer..."
                sleep 2
                if [ ! -S "$socket_path" ]; then
                    log_error "socket_vmnet daemon started but socket not available at $socket_path"
                    exit 1
                fi
            fi
        else
            log_error "Failed to start socket_vmnet daemon"
            exit 1
        fi
    fi
}

socket_vmnet_init() {
    if ! socket_vmnet_status; then
        log_warning "socket_vmnet daemon not running"
        log_info "This is required for bridged networking without sudo on each VM start"
        printf "Start socket_vmnet daemon? (requires sudo once) (y/N): "
        read -r confirm
        
        if [ "$confirm" = "y" ] || [ "$confirm" = "Y" ]; then
            socket_vmnet_start
        else
            log_info "You can start it later with: sudo brew services start socket_vmnet"
            log_info "Or use: v4m v4m_init"
            exit 1
        fi
    # else
    #     log_success "socket_vmnet daemon is running"
    fi
}

check_setup_status() {
    local issues=0
    
    # Check dependencies
    if ! command -v qemu-system-aarch64 >/dev/null 2>&1; then
        issues=$((issues + 1))
    fi
    
    if ! brew list socket_vmnet >/dev/null 2>&1; then
        issues=$((issues + 1))
    fi
    
    if ! command -v socat >/dev/null 2>&1; then
        issues=$((issues + 1))
    fi
    
    # Check socket_vmnet service
    if ! pgrep -f socket_vmnet >/dev/null 2>&1; then
        issues=$((issues + 1))
    else
        local brew_prefix
        if command -v brew >/dev/null 2>&1; then
            brew_prefix=$(brew --prefix)
        else
            brew_prefix="/opt/homebrew"
        fi
        
        if [ ! -S "$brew_prefix/var/run/socket_vmnet" ]; then
            issues=$((issues + 1))
        fi
    fi
    
    return $issues
}

install_dependencies() {
    log_info "Checking and installing dependencies..."
    echo
    
    # Check and install QEMU
    if ! command -v qemu-system-aarch64 >/dev/null 2>&1; then
        log_warning "QEMU not found"
        log_info "Installing QEMU..."
        brew install qemu
        log_success "QEMU installed"
    else
        log_success "QEMU already installed"
    fi
    
    # Check and install socket_vmnet
    if ! brew list socket_vmnet >/dev/null 2>&1; then
        log_warning "socket_vmnet not found"
        log_info "Installing socket_vmnet..."
        brew install socket_vmnet
        log_success "socket_vmnet installed"
    else
        log_success "socket_vmnet already installed"
    fi
    
    # Check and install socat
    if ! command -v socat >/dev/null 2>&1; then
        log_warning "socat not found"
        log_info "Installing socat..."
        brew install socat
        log_success "socat installed"
    else
        log_success "socat already installed"
    fi
}

apply_dhcp_fixes() {
    log_info "Configuring macOS for VM networking (DHCP fixes)..."
    echo
    
    # Fix macOS firewall blocking DHCP
    log_info "Configuring macOS firewall to allow bootpd (DHCP server)..."
    if sudo /usr/libexec/ApplicationFirewall/socketfilterfw --add /usr/libexec/bootpd 2>/dev/null; then
        log_success "Added bootpd to firewall"
    else
        log_info "bootpd already in firewall (or failed to add)"
    fi
    
    if sudo /usr/libexec/ApplicationFirewall/socketfilterfw --unblock /usr/libexec/bootpd 2>/dev/null; then
        log_success "Unblocked bootpd in firewall"
    else
        log_info "bootpd already unblocked (or failed to unblock)"
    fi
    
    # Restart DHCP service
    log_info "Restarting macOS DHCP service..."
    if sudo /bin/launchctl kickstart -kp system/com.apple.bootpd; then
        log_success "DHCP service restarted"
    else
        log_warning "Failed to restart DHCP service (may still work)"
    fi
    
    # Get homebrew prefix
    local brew_prefix
    if command -v brew >/dev/null 2>&1; then
        brew_prefix=$(brew --prefix)
    else
        brew_prefix="/opt/homebrew"
    fi
    
    # Ensure run directory exists with correct permissions
    local run_dir="$brew_prefix/var/run"
    if [ ! -d "$run_dir" ]; then
        log_info "Creating run directory..."
        sudo mkdir -p "$run_dir"
        sudo chown "$(whoami):$(id -gn)" "$run_dir"
        sudo chmod 755 "$run_dir"
    fi
    
    # Start socket_vmnet service
    log_info "Starting socket_vmnet service..."
    if sudo brew services start socket_vmnet; then
        log_success "socket_vmnet service started"
        sleep 2  # Give it time to create socket
        
        # Verify socket was created
        local socket_path="$brew_prefix/var/run/socket_vmnet"
        if [ -S "$socket_path" ]; then
            log_success "socket_vmnet socket created successfully"
        else
            log_warning "socket_vmnet service started but socket not found"
        fi
    else
        log_error "Failed to start socket_vmnet service"
        return 1
    fi
}

v4m_init() {
    local deps_only=false
    local dhcp_only=false
    local check_only=false
    
    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            --deps-only)
                deps_only=true
                shift
                ;;
            --dhcp-only)
                dhcp_only=true
                shift
                ;;
            --check)
                check_only=true
                shift
                ;;
            *)
                shift
                ;;
        esac
    done
    
    if [ "$check_only" = true ]; then
        log_info "Checking v4m setup status..."
        echo
        
        local issues=0
        
        # Check dependencies
        log_info "Dependency Status:"
        
        if command -v qemu-system-aarch64 >/dev/null 2>&1; then
            log_success "QEMU found: $(qemu-system-aarch64 --version | head -1)"
        else
            log_error "QEMU not found"
            issues=$((issues + 1))
        fi
        
        if brew list socket_vmnet >/dev/null 2>&1; then
            log_success "socket_vmnet found: $(brew list --versions socket_vmnet)"
        else
            log_error "socket_vmnet not found"
            issues=$((issues + 1))
        fi
        
        if command -v socat >/dev/null 2>&1; then
            log_success "socat found: $(socat -V | head -1)"
        else
            log_error "socat not found"
            issues=$((issues + 1))
        fi
        
        echo
        log_info "Service Status:"
        
        # Check socket_vmnet service
        if pgrep -f socket_vmnet >/dev/null 2>&1; then
            local brew_prefix
            if command -v brew >/dev/null 2>&1; then
                brew_prefix=$(brew --prefix)
            else
                brew_prefix="/opt/homebrew"
            fi
            
            if [ -S "$brew_prefix/var/run/socket_vmnet" ]; then
                log_success "socket_vmnet service running and socket accessible"
            else
                log_warning "socket_vmnet process running but socket not accessible"
                issues=$((issues + 1))
            fi
        else
            log_error "socket_vmnet service not running"
            issues=$((issues + 1))
        fi
        
        echo
        if [ $issues -eq 0 ]; then
            log_success "All checks passed! v4m should work properly."
        else
            log_warning "Found $issues issue(s). Run 'v4m v4m_init' to fix."
        fi
        
        return $issues
    fi
    
    echo "🖥️  v4m Setup Script"
    echo "=================="
    echo
    
    if [ "$dhcp_only" = false ]; then
        install_dependencies
        echo
    fi
    
    if [ "$deps_only" = false ]; then
        apply_dhcp_fixes
        echo
    fi
    
    log_success "v4m setup completed successfully!"
    echo
    log_info "Next steps:"
    echo "  1. Create a VM: v4m vm create --name myvm"
    echo "  2. Connect to console: v4m vm console myvm"
    echo "  3. SSH to VM: ssh user01@myvm.local"
}

ensure_v4m_setup() {
    if ! check_setup_status; then
        log_warning "v4m is not properly set up"
        log_info "Running automatic setup..."
        echo
        v4m_init
        echo
    fi
}

# VM Commands
vm_create() {
    ensure_v4m_setup
    
    local vm_name=""
    local image="$DEFAULT_IMAGE"
    local username="$DEFAULT_USER"
    local password=""
    
    while [[ $# -gt 0 ]]; do
        case $1 in
            --name) vm_name="$2"; shift 2 ;;
            --image) image="$2"; shift 2 ;;
            --user) username="$2"; shift 2 ;;
            --pass) password="$2"; shift 2 ;;
            *) log_error "Unknown option: $1"; exit 1 ;;
        esac
    done
    
    if [ -z "$vm_name" ]; then
        vm_name=$(generate_vm_name)
    else
        local original_name="$vm_name"
        vm_name=$(sanitize_vm_name "$vm_name")
        if [ "$original_name" != "$vm_name" ]; then
            log_warning "VM name sanitized: '$original_name' → '$vm_name'"
        fi
    fi
    
    if [ -z "$password" ]; then
        password=$(generate_password)
    fi
    
    init_dirs
    
    
    create_vm_internal "$vm_name" "$image" "$username" "$password"
}

get_vm_ip() {
    local vm_name="$1"
    local ip=""
    
    # Try mDNS resolution first (works with fixed DHCP)
    if ping -c 1 -W 500 "$vm_name.local" >/dev/null 2>&1; then
        ip=$(ping -c 1 "$vm_name.local" 2>/dev/null | head -1 | grep -oE '([0-9]{1,3}\.){3}[0-9]{1,3}')
    fi
    
    echo "$ip"
}

get_vm_disk_info() {
    local vm_dir="$1"
    local vm_disk="$vm_dir/disk.qcow2"
    local size_info=""
    local usage_info=""
    
    if [ -f "$vm_disk" ]; then
        # Get actual disk size (allocated)
        usage_info=$(du -h "$vm_disk" 2>/dev/null | cut -f1)
        
        # Get virtual disk size using qemu-img info
        if command -v qemu-img >/dev/null 2>&1; then
            size_info=$(qemu-img info "$vm_disk" 2>/dev/null | grep 'virtual size' | cut -d'(' -f2 | cut -d' ' -f1)
            # Convert bytes to human readable if it's just a number
            if [[ "$size_info" =~ ^[0-9]+$ ]]; then
                size_info=$(echo "$size_info" | awk '{print ($1/1024/1024/1024)"G"}')
            fi
        fi
        
        # Fallback to configured size if qemu-img fails
        if [ -z "$size_info" ]; then
            size_info="20G"  # Default size
        fi
    else
        size_info="-"
        usage_info="-"
    fi
    
    echo "$size_info|$usage_info"
}

vm_list() {
    init_dirs
    echo -e "\n${YELLOW}Virtual Machines:${NC}\n"
    
    if [ ! "$(ls -A "$VMS_DIR" 2>/dev/null)" ]; then
        echo "  No VMs found"
        return
    fi
    
    # Table header
    printf "%-15s %-10s %-5s %-8s %-10s %-10s %-15s %-10s\n" "NAME" "IMAGE" "CPUS" "MEMORY" "DISK SIZE" "DISK USED" "IP" "STATUS"
    printf "%-15s %-10s %-5s %-8s %-10s %-10s %-15s %-10s\n" "----" "-----" "-----" "------" "---------" "---------" "--" "------"
    
    for vm_dir in "$VMS_DIR"/*; do
        if [ -d "$vm_dir" ]; then
            local vm_name=$(basename "$vm_dir")
            local vm_info="$vm_dir/vm-info.json"
            local pid_file="$vm_dir/vm.pid"
            
            if [ -f "$vm_info" ]; then
                local image=$(grep '"image"' "$vm_info" | cut -d'"' -f4)
                local cpus=$(grep '"cpus"' "$vm_info" | cut -d'"' -f4)
                local memory_mb=$(grep '"memory"' "$vm_info" | cut -d'"' -f4)
                local ip="-"
                local status="stopped"
                
                # Convert memory from MB to GB
                local memory_gb=$((memory_mb / 1024))
                if [ $memory_gb -eq 0 ]; then
                    memory_gb="<1GB"
                else
                    memory_gb="${memory_gb}GB"
                fi
                
                # Get disk information
                local disk_info=$(get_vm_disk_info "$vm_dir")
                local disk_size=$(echo "$disk_info" | cut -d'|' -f1)
                local disk_usage=$(echo "$disk_info" | cut -d'|' -f2)
                
                if [ -f "$pid_file" ] && kill -0 "$(cat "$pid_file")" 2>/dev/null; then
                    status="${GREEN}running${NC}"
                    ip=$(get_vm_ip "$vm_name")
                    [ -z "$ip" ] && ip="-"
                else
                    status="${GRAY}stopped${NC}"
                fi
                
                printf "%-15s %-10s %-5s %-8s %-10s %-10s %-15s %b\n" "$vm_name" "$image" "$cpus" "$memory_gb" "$disk_size" "$disk_usage" "$ip" "$status"
            fi
        fi
    done
}

vm_start() {
    ensure_v4m_setup
    
    local vm_name="$1"
    if [ -z "$vm_name" ]; then
        log_error "VM name required"
        exit 1
    fi
    
    local vm_dir="$VMS_DIR/$vm_name"
    if [ ! -d "$vm_dir" ]; then
        log_error "VM '$vm_name' not found"
        exit 1
    fi
    
    local pid_file="$vm_dir/vm.pid"
    if [ -f "$pid_file" ] && kill -0 "$(cat "$pid_file")" 2>/dev/null; then
        log_warning "VM '$vm_name' is already running"
        return
    fi
    
    local vm_info="$vm_dir/vm-info.json"
    local vm_mac=$(grep '"mac"' "$vm_info" | cut -d'"' -f4)
    
    start_vm_internal "$vm_name" "$vm_mac" "$vm_dir"
}

vm_stop() {
    local vm_name="$1"
    if [ -z "$vm_name" ]; then
        log_error "VM name required"
        exit 1
    fi
    
    local vm_dir="$VMS_DIR/$vm_name"
    local pid_file="$vm_dir/vm.pid"
    
    if [ ! -f "$pid_file" ]; then
        log_warning "VM '$vm_name' is not running"
        return
    fi
    
    local pid=$(cat "$pid_file")
    if kill -0 "$pid" 2>/dev/null; then
        kill "$pid"
        rm -f "$pid_file"
        log_success "VM '$vm_name' stopped"
    else
        rm -f "$pid_file"
        log_warning "VM '$vm_name' was not running"
    fi
}

vm_delete() {
    local vm_name="$1"
    if [ -z "$vm_name" ]; then
        log_error "VM name required"
        exit 1
    fi
    
    local vm_dir="$VMS_DIR/$vm_name"
    if [ ! -d "$vm_dir" ]; then
        log_error "VM '$vm_name' not found"
        exit 1
    fi
    
    # Check if VM is running
    local pid_file="$vm_dir/vm.pid"
    if [ -f "$pid_file" ] && kill -0 "$(cat "$pid_file")" 2>/dev/null; then
        log_warning "VM '$vm_name' is currently running"
        printf "Stop and delete VM '$vm_name'? This action cannot be undone (y/N): "
        read -r confirm
        
        if [ "$confirm" = "y" ] || [ "$confirm" = "Y" ]; then
            log_info "Stopping VM '$vm_name'..."
            vm_stop "$vm_name"
        else
            log_info "Delete cancelled"
            exit 0
        fi
    else
        printf "Delete VM '$vm_name'? This action cannot be undone (y/N): "
        read -r confirm
        
        if [ "$confirm" != "y" ] && [ "$confirm" != "Y" ]; then
            log_info "Delete cancelled"
            exit 0
        fi
    fi
    
    rm -rf "$vm_dir"
    log_success "VM '$vm_name' deleted"
}

vm_ip() {
    local vm_name="$1"
    if [ -z "$vm_name" ]; then
        log_error "VM name required"
        exit 1
    fi
    
    local vm_dir="$VMS_DIR/$vm_name"
    if [ ! -d "$vm_dir" ]; then
        log_error "VM '$vm_name' not found"
        exit 1
    fi
    
    local pid_file="$vm_dir/vm.pid"
    if [ ! -f "$pid_file" ] || ! kill -0 "$(cat "$pid_file")" 2>/dev/null; then
        log_error "VM '$vm_name' is not running"
        exit 1
    fi
    
    local ip=$(get_vm_ip "$vm_name")
    if [ -n "$ip" ]; then
        echo "$ip"
    else
        log_error "Could not determine IP for VM '$vm_name'. Try: ssh user@$vm_name.local"
        exit 1
    fi
}

vm_console() {
    ensure_v4m_setup
    
    local vm_name="$1"
    if [ -z "$vm_name" ]; then
        log_error "VM name required"
        exit 1
    fi
    
    local vm_dir="$VMS_DIR/$vm_name"
    if [ ! -d "$vm_dir" ]; then
        log_error "VM '$vm_name' not found"
        exit 1
    fi
    
    local pid_file="$vm_dir/vm.pid"
    if [ ! -f "$pid_file" ] || ! kill -0 "$(cat "$pid_file")" 2>/dev/null; then
        log_error "VM '$vm_name' is not running"
        exit 1
    fi
    
    local console_sock="$vm_dir/console.sock"
    if [ ! -S "$console_sock" ]; then
        log_error "Console socket not found for VM '$vm_name'"
        exit 1
    fi
    
    log_info "Connecting to console for VM '$vm_name'"
    log_info "Press Ctrl+C to disconnect"
    echo
    
    
    socat - UNIX-CONNECT:"$console_sock"
}


# Image Commands
image_list() {
    init_dirs
    echo -e "${YELLOW}Available Images:${NC}"
    
    if [ ! "$(ls -A "$IMAGES_DIR" 2>/dev/null)" ]; then
        echo "  No images found"
        return
    fi
    
    for image_dir in "$IMAGES_DIR"/*; do
        if [ -d "$image_dir" ]; then
            local image_name=$(basename "$image_dir")
            local image_file=$(ls "$image_dir"/*.qcow2 "$image_dir"/*.img 2>/dev/null | head -1)
            
            if [ -n "$image_file" ]; then
                local size=$(du -h "$image_file" | cut -f1)
                echo "  📦 $image_name ($size)"
            fi
        fi
    done
}

image_pull() {
    local image="$1"
    if [ -z "$image" ]; then
        log_error "Image name required (debian12, ubuntu22, ubuntu24)"
        exit 1
    fi
    
    init_dirs
    ensure_image "$image" >/dev/null
}

image_delete() {
    local image="$1"
    if [ -z "$image" ]; then
        log_error "Image name required"
        exit 1
    fi
    
    local image_dir="$IMAGES_DIR/$image"
    if [ ! -d "$image_dir" ]; then
        log_error "Image '$image' not found"
        exit 1
    fi
    
    rm -rf "$image_dir"
    log_success "Image '$image' deleted"
}

purge() {
    init_dirs
    
    local vm_count=0
    local image_count=0
    local running_vms=0
    
    # Count VMs
    if [ -d "$VMS_DIR" ] && [ "$(ls -A "$VMS_DIR" 2>/dev/null)" ]; then
        vm_count=$(ls -1 "$VMS_DIR" | wc -l | tr -d ' ')
        
        # Count running VMs
        for vm_dir in "$VMS_DIR"/*; do
            if [ -d "$vm_dir" ]; then
                local pid_file="$vm_dir/vm.pid"
                if [ -f "$pid_file" ] && kill -0 "$(cat "$pid_file")" 2>/dev/null; then
                    running_vms=$((running_vms + 1))
                fi
            fi
        done
    fi
    
    # Count images
    if [ -d "$IMAGES_DIR" ] && [ "$(ls -A "$IMAGES_DIR" 2>/dev/null)" ]; then
        image_count=$(ls -1 "$IMAGES_DIR" | wc -l | tr -d ' ')
    fi
    
    if [ "$vm_count" -eq 0 ] && [ "$image_count" -eq 0 ]; then
        log_info "No VMs or images found to purge"
        return
    fi
    
    echo
    log_warning "PURGE ALL DATA"
    echo "This will permanently delete:"
    if [ "$vm_count" -gt 0 ]; then
        echo "  • $vm_count VM(s) (including $running_vms running)"
    fi
    if [ "$image_count" -gt 0 ]; then
        echo "  • $image_count image(s)"
    fi
    echo "  • All VM data and configurations"
    echo
    log_error "This action cannot be undone!"
    echo
    
    printf "Type 'DELETE ALL' to confirm purge: "
    read -r confirm
    
    if [ "$confirm" != "DELETE ALL" ]; then
        log_info "Purge cancelled"
        exit 0
    fi
    
    echo
    log_info "Purging all VMs and images..."
    
    # Stop and delete all VMs
    if [ "$vm_count" -gt 0 ]; then
        log_info "Stopping and deleting $vm_count VM(s)..."
        for vm_dir in "$VMS_DIR"/*; do
            if [ -d "$vm_dir" ]; then
                local vm_name=$(basename "$vm_dir")
                local pid_file="$vm_dir/vm.pid"
                
                # Stop VM if running
                if [ -f "$pid_file" ] && kill -0 "$(cat "$pid_file")" 2>/dev/null; then
                    local pid=$(cat "$pid_file")
                    kill "$pid" 2>/dev/null
                    log_info "  Stopped VM '$vm_name'"
                fi
                
                # Delete VM directory
                rm -rf "$vm_dir"
                log_info "  Deleted VM '$vm_name'"
            fi
        done
    fi
    
    # Delete all images
    if [ "$image_count" -gt 0 ]; then
        log_info "Deleting $image_count image(s)..."
        rm -rf "$IMAGES_DIR"/*
        log_info "  Deleted all images"
    fi
    
    echo
    log_success "Purge completed successfully"
    log_info "All VMs and images have been removed"
}

# Internal functions
ensure_image() {
    local image="$1"
    local url=$(get_image_url "$image")
    
    if [ -z "$url" ]; then
        log_error "Unknown image: $image"
        log_info "Available images: debian12, ubuntu22, ubuntu24"
        exit 1
    fi
    
    local filename=$(basename "$url")
    local image_dir="$IMAGES_DIR/$image"
    local image_path="$image_dir/$filename"
    
    if [ -f "$image_path" ]; then
        echo "$image_path"
        return
    fi
    
    # Redirect spinner output to stderr to avoid interfering with return value
    show_spinner "Downloading $image" 100 >&2 &
    local spinner_pid=$!
    mkdir -p "$image_dir"
    if curl -L -o "$image_path" "$url" --silent; then
        kill $spinner_pid 2>/dev/null
        printf "\r\033[K" >&2
        log_success "Downloaded $image" >&2
        echo "$image_path"
    else
        kill $spinner_pid 2>/dev/null
        printf "\r\033[K" >&2
        log_error "Failed to download $image" >&2
        rm -f "$image_path"
        exit 1
    fi
}

create_cloud_init() {
    local vm_name="$1"
    local username="$2"
    local password="$3"
    local vm_dir="$4"
    
    local hashed_pass=$(hash_password "$password")
    
    cat > "$vm_dir/user-data" << EOF
#cloud-config

hostname: $vm_name
fqdn: $vm_name.local
timezone: Europe/Rome

ssh_pwauth: true
disable_root: false

network:
  version: 2
  ethernets:
    enp0s1:
      dhcp4: true
      dhcp6: true
      dhcp-identifier: mac
      optional: true

users:
  - name: $username
    sudo: ALL=(ALL) NOPASSWD:ALL
    groups: [sudo, users]
    shell: /bin/bash
    lock_passwd: false
    passwd: $hashed_pass
  - name: root
    lock_passwd: false
    passwd: $hashed_pass

packages:
  - openssh-server
  - sudo
  - curl
  - wget
  - vim
  - net-tools
  - htop
  - avahi-daemon
  - avahi-utils

runcmd:
  - systemctl enable ssh
  - systemctl start ssh
  - systemctl enable avahi-daemon
  - systemctl start avahi-daemon
  - echo "VM is ready!" > /tmp/vm-ready

final_message: "VM $vm_name is ready! SSH available on port 22."
EOF

    cat > "$vm_dir/meta-data" << EOF
instance-id: $vm_name-$(date +%s)
local-hostname: $vm_name
EOF
}

create_vm_internal() {
    local vm_name="$1"
    local image="$2"
    local username="$3"
    local password="$4"
    
    local image_path=$(ensure_image "$image")
    
    local vm_dir="$VMS_DIR/$vm_name"
    if [ -d "$vm_dir" ]; then
        log_error "VM $vm_name already exists"
        exit 1
    fi
    mkdir -p "$vm_dir"
    
    local vm_disk="$vm_dir/disk.qcow2"
    cp "$image_path" "$vm_disk"
    qemu-img resize "$vm_disk" "$DEFAULT_DISK_SIZE" >/dev/null
    
    local vm_mac=$(generate_mac)
    
    local efi_vars="$vm_dir/efi-vars.fd"
    if [ -f "/opt/homebrew/share/qemu/edk2-aarch64-vars.fd" ]; then
        cp "/opt/homebrew/share/qemu/edk2-aarch64-vars.fd" "$efi_vars"
    else
        dd if=/dev/zero of="$efi_vars" bs=1M count=64 >/dev/null 2>&1
    fi
    
    create_cloud_init "$vm_name" "$username" "$password" "$vm_dir"
    
    local cloud_init_iso="$vm_dir/cloud-init.iso"
    local temp_dir="/tmp/cloud-init-$$"
    mkdir -p "$temp_dir"
    cp "$vm_dir/user-data" "$vm_dir/meta-data" "$temp_dir/"
    
    if ! hdiutil makehybrid -iso -joliet -default-volume-name "cidata" -o "$cloud_init_iso" "$temp_dir" >/dev/null 2>&1; then
        log_error "Failed to create cloud-init ISO"
        rm -rf "$temp_dir" "$vm_dir"
        exit 1
    fi
    rm -rf "$temp_dir"
    
    cat > "$vm_dir/vm-info.json" << EOF
{
    "name": "$vm_name",
    "image": "$image",
    "username": "$username",
    "password": "$password",
    "mac": "$vm_mac",
    "memory": "$DEFAULT_MEMORY",
    "cpus": "$DEFAULT_CPUS",
    "disk_size": "$DEFAULT_DISK_SIZE",
    "created": "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
}
EOF
    
    start_vm_internal "$vm_name" "$vm_mac" "$vm_dir"
}

start_vm_internal() {
    local vm_name="$1"
    local vm_mac="$2"
    local vm_dir="$3"
    
    local vm_disk="$vm_dir/disk.qcow2"
    local cloud_init_iso="$vm_dir/cloud-init.iso"
    local efi_vars="$vm_dir/efi-vars.fd"
    local log_file="$vm_dir/console.log"
    local pid_file="$vm_dir/vm.pid"
    
    > "$log_file"
    
    # Get homebrew prefix dynamically
    local brew_prefix
    if command -v brew >/dev/null 2>&1; then
        brew_prefix=$(brew --prefix)
    else
        brew_prefix="/opt/homebrew"
    fi
    
    local socket_vmnet_sock="$brew_prefix/var/run/socket_vmnet"
    local socket_vmnet_client="$brew_prefix/opt/socket_vmnet/bin/socket_vmnet_client"
    
    # Verify socket_vmnet_client exists
    if [ ! -x "$socket_vmnet_client" ]; then
        log_error "socket_vmnet_client not found at $socket_vmnet_client"
        log_info "Install with: brew install socket_vmnet"
        exit 1
    fi
    
    # Verify socket exists
    if [ ! -S "$socket_vmnet_sock" ]; then
        log_error "socket_vmnet socket not found at $socket_vmnet_sock"
        log_info "Make sure socket_vmnet daemon is running: sudo brew services start socket_vmnet"
        exit 1
    fi
    
    # Build QEMU arguments for socket_vmnet_client
    local qemu_args=(
        -machine virt,highmem=on
        -cpu host
        -accel hvf
        -smp "$DEFAULT_CPUS"
        -m "$DEFAULT_MEMORY"
        -drive "if=pflash,format=raw,file=$brew_prefix/share/qemu/edk2-aarch64-code.fd,readonly=on"
        -drive "if=pflash,format=raw,file=$efi_vars"
        -drive "file=$vm_disk,format=qcow2,if=virtio"
        -netdev "socket,id=net0,fd=3"
        -device "virtio-net-device,netdev=net0,mac=$vm_mac"
        -serial "unix:$vm_dir/console.sock,server,nowait"
        -nographic
    )
    
    # Add cloud-init ISO only for first boot
    if [ ! -f "$vm_dir/.first_boot_complete" ]; then
        qemu_args+=(-drive "file=$cloud_init_iso,media=cdrom,if=virtio,readonly=on")
        touch "$vm_dir/.first_boot_complete"
    fi
    
    # Start QEMU with socket_vmnet_client wrapper
    nohup "$socket_vmnet_client" "$socket_vmnet_sock" qemu-system-aarch64 "${qemu_args[@]}" > "$log_file" 2>&1 &
    
    local qemu_pid=$!
    echo $qemu_pid > "$pid_file"
    disown $qemu_pid
    
    local boot_time=200
    local spin='⠋⠙⠹⠸⠼⠴⠦⠧⠇⠏'
    local spin_length=${#spin}
    
    tput civis
    for i in $(seq 1 $boot_time); do
        local spinner_char=$((i % spin_length))
        printf "\r${BLUE}${spin:$spinner_char:1}${NC} Starting VM $vm_name (may take up to 1 minute)..."
        sleep 0.1
        
        if ! kill -0 "$qemu_pid" 2>/dev/null; then
            printf "\r\033[K"
            tput cnorm
            log_error "VM $vm_name stopped unexpectedly"
            log_info "Check log: $log_file"
            exit 1
        fi
    done
    tput cnorm
    
    printf "\r\033[K"
    log_success "VM $vm_name is ready!"
    
    show_vm_info "$vm_name" "$vm_dir"
}

show_vm_info() {
    local vm_name="$1"
    local vm_dir="$2"
    local vm_info="$vm_dir/vm-info.json"
    
    if [ ! -f "$vm_info" ]; then
        log_error "VM info file not found"
        return
    fi
    
    local username=$(grep '"username"' "$vm_info" | cut -d'"' -f4)
    local password=$(grep '"password"' "$vm_info" | cut -d'"' -f4)
    
    echo
    echo -e "${YELLOW}VM Information:${NC}"
    echo "  🖥️  Name: $vm_name"
    echo "  💾 Memory: ${DEFAULT_MEMORY}MB"
    echo "  🔧 CPUs: $DEFAULT_CPUS"
    echo
    echo -e "${YELLOW}Login Credentials:${NC}"
    echo "  👤 Username: $username"
    echo "  🔑 Password: $password"
    echo "  👑 Root password: $password (same as user)"
    echo "  📺 SSH: ssh $username@$vm_name.local"
    echo
    echo -e "${YELLOW}VM Management:${NC}"
    echo "  ⏹️  Stop: v4m vm stop $vm_name"
    echo
}

show_help() {
    echo "v4m - VM Manager for macOS"
    echo
    echo "Usage: v4m <command> [options]"
    echo
    echo "Setup Commands:"
    echo "  v4m_init [--deps-only] [--dhcp-only] [--check]  Complete setup with options"
    echo "  init                        Initialize socket_vmnet only (basic setup)"
    echo
    echo "VM Commands:"
    echo "  vm create [--name NAME] [--image IMAGE] [--user USER] [--pass PASS]"
    echo "  vm list                     List all VMs with status and IPs"
    echo "  vm start <name>             Start a VM (no sudo required after init)"
    echo "  vm stop <name>              Stop a VM"
    echo "  vm delete <name>            Delete a VM"
    echo "  vm ip <name>                Get VM IP address"
    echo "  vm console <name>           Connect to VM console (Ctrl+C to exit)"
    echo
    echo "Image Commands:"
    echo "  image list                  List available images"
    echo "  image pull <image>          Download an image"
    echo "  image delete <image>        Delete an image"
    echo
    echo "Cleanup Commands:"
    echo "  purge                       Delete ALL VMs and images (requires confirmation)"
    echo
    echo "Available images: debian12, ubuntu22, ubuntu24"
    echo
    echo "DHCP Fix Explanation:"
    echo "  v4m_init fixes macOS firewall blocking DHCP by:"
    echo "  - Allowing bootpd (DHCP server) through firewall"
    echo "  - Restarting macOS DHCP service"
    echo "  - Configuring socket_vmnet properly"
    echo "  This ensures VMs get IPv4 addresses automatically"
    echo
    echo "Examples:"
    echo "  v4m v4m_init                          # Complete setup (recommended first run)"
    echo "  v4m v4m_init --check                  # Check current setup status"
    echo "  v4m vm create                         # Create VM with random name (auto-setup if needed)"
    echo "  v4m vm create --name myvm --image debian12  # Create VM with specific name and image"
    echo "  v4m vm list                           # List all VMs with IPs"
    echo "  v4m vm console myvm                   # Connect to VM console (auto-setup if needed)"
    echo "  v4m purge                             # Delete everything (requires 'DELETE ALL')"
    echo "  ssh user01@myvm.local                 # SSH to VM (after setup)"
}

main() {
    if [ $# -eq 0 ]; then
        show_help
        exit 0
    fi
    
    case "$1" in
        "v4m_init")
            shift; v4m_init "$@"
            ;;
        "init")
            socket_vmnet_init
            ;;
        "vm")
            shift
            case "$1" in
                "create") shift; vm_create "$@" ;;
                "list") vm_list ;;
                "start") shift; vm_start "$@" ;;
                "stop") shift; vm_stop "$@" ;;
                "delete") shift; vm_delete "$@" ;;
                "ip") shift; vm_ip "$@" ;;
                "console") shift; vm_console "$@" ;;
                *) log_error "Unknown vm command: $1"; show_help; exit 1 ;;
            esac
            ;;
        "image")
            shift
            case "$1" in
                "list") image_list ;;
                "pull") shift; image_pull "$@" ;;
                "delete") shift; image_delete "$@" ;;
                *) log_error "Unknown image command: $1"; show_help; exit 1 ;;
            esac
            ;;
        "purge")
            purge
            ;;
        "-h"|"--help"|"help")
            show_help
            ;;
        *)
            log_error "Unknown command: $1"
            show_help
            exit 1
            ;;
    esac
}

main "$@"